ASUS Router Security News Automation  
é€™æ˜¯ä¸€å€‹ç«¯åˆ°ç«¯çš„è³‡å®‰æ–°èè‡ªå‹•åŒ–è’é›†ç³»çµ±ã€‚  
å°ˆæ¡ˆç›®æ¨™æ˜¯å¾å¤šå€‹ä¾†æºï¼ˆGoogle Newsã€å®˜æ–¹å…¬å‘Šã€è³‡å®‰è«–å£‡ï¼‰çˆ¬å– ASUS Router ç›¸é—œè³‡å®‰å¨è„…ï¼Œç¶“éæ¸…æ´—èˆ‡å»é‡å¾Œå­˜å…¥ MySQLï¼Œæœ€å¾Œè‡ªå‹•å¡«å¯«è‡³ Google è¡¨å–®ä»¥é€²è¡Œé€šå ±ã€‚  

ğŸŒŸ å°ˆæ¡ˆäº®é»  
æœ¬å°ˆæ¡ˆåŒ…å«è¨±å¤šé‡å° ç€è¦½å™¨è‡ªå‹•åŒ– (Browser Automation) çš„é€²éšå·¥ç¨‹å¯¦è¸ï¼š  
1. å…¨ Selenium æ¶æ§‹ï¼šæœå°‹èˆ‡å…§æ–‡é–±è®€çš†æ¡ç”¨ Seleniumï¼Œä¸¦å¯¦ä½œ Anti-Detect æ©Ÿåˆ¶ç¹éç¶²ç«™é˜²è­·ã€‚  
2. é«˜ç©©å®šæ€§è¨­è¨ˆ (Resilience)ï¼š  
   Eager Loading ç­–ç•¥ï¼šå¤§å¹…ç¸®çŸ­é é¢è¼‰å…¥ç­‰å¾…æ™‚é–“ï¼Œé˜²æ­¢çˆ¬èŸ²å¡æ­»ã€‚  
   Driver è‡ªå‹•å¾©æ´»ï¼šåµæ¸¬åˆ°åº•å±¤é€£ç·š (HTTPConnectionPool) éŒ¯èª¤æ™‚ï¼Œæœƒè‡ªå‹•é‡å•Ÿç€è¦½å™¨ï¼Œå¯¦ç¾ç„¡äººå€¼å®ˆé‹è¡Œã€‚  
3.è¨˜æ†¶é«”ç®¡ç†ï¼šå¯¦ä½œ gc.collect() èˆ‡ä¸»å‹•é—œé–‰ Driverï¼Œä½¿ç”¨åƒæ•¸é˜²æ­¢ Docker è¨˜æ†¶é«”å´©æ½°ï¼Œé˜²æ­¢ Docker OOMã€‚  
4.ç²¾æº–éæ¿¾ï¼šå…§å»ºå¤šèªç³»é—œéµå­—éæ¿¾å™¨ï¼Œç¢ºä¿æ–°èèˆ‡ã€ŒASUSã€åŠã€ŒRouter/è³‡å®‰ã€é«˜åº¦ç›¸é—œã€‚  
5.æ™ºæ…§å¡«è¡¨ï¼šä½¿ç”¨ JavaScript Injection æŠ€è¡“ï¼Œè§£æ±º Google è¡¨å–®è¼¸å…¥æ¡†ä¸å¯äº’å‹• (Not Interactable) çš„å•é¡Œã€‚  

ğŸ›  æŠ€è¡“å †ç–Š (Tech Stack)  
```text
**Language**: Python 3.9+  
**Database**: MySQL 8.0 (Dockerized)  
**Core Library**: Selenium WebDriver (Headless Chrome)  
**Infrastructure**: Docker & Docker Compose  
**Features**: Multi-source Scraping (Google News EN/TW, Official Sites)  
              Timezone Correction (UTC+8)  
              Automatic Log Rotation (æ—¥èªŒè¼ªæ›¿ï¼ŒæŒ‰æ—¥å„²å­˜)  
              404 & PDF Detection (ç„¡æ•ˆé€£çµéæ¿¾)  
```

ğŸ“‚ å°ˆæ¡ˆçµæ§‹  
```text
asus-news/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py             # ä¸»ç¨‹å¼ (è² è²¬æ’ç¨‹ã€å¤šæºæœå°‹é‚è¼¯)
â”‚   â”œâ”€â”€ scraper.py          # çˆ¬èŸ²æ ¸å¿ƒ (å«ååµæ¸¬ã€é‡å•Ÿæ©Ÿåˆ¶ã€Eageræ¨¡å¼)
â”‚   â”œâ”€â”€ form_filler.py      # å¡«è¡¨æ©Ÿå™¨äºº (å« JS æ³¨å…¥ã€æ™‚å€æ ¡æ­£)
â”‚   â”œâ”€â”€ database.py         # è³‡æ–™åº«æ“ä½œ (å«å»é‡é‚è¼¯)
â”‚   â”œâ”€â”€ logger.py           # æ—¥èªŒæ¨¡çµ„ (æ”¯æ´è¼ªæ›¿èˆ‡é›™é‡è¼¸å‡º)
â”‚   â””â”€â”€ utils.py            # å·¥å…·åŒ… (æ—¥æœŸè§£æ)
â”œâ”€â”€ db/
â”‚   â””â”€â”€ init.sql            # è³‡æ–™åº«åˆå§‹åŒ–è…³æœ¬
â”œâ”€â”€ logs/                   # åŸ·è¡Œæ—¥èªŒ (è‡ªå‹•ç”Ÿæˆï¼ŒæŒ‰æ—¥è¼ªæ›¿)
â”œâ”€â”€ .env                    # ç’°å¢ƒè®Šæ•¸è¨­å®š (éœ€è‡ªè¡Œå»ºç«‹)
â”œâ”€â”€ docker-compose.yml      # å®¹å™¨ç·¨æ’è¨­å®š (å«è¨˜æ†¶é«”å„ªåŒ–)
â”œâ”€â”€ Dockerfile              # Python ç’°å¢ƒå®šç¾©
â””â”€â”€ requirements.txt        # å¥—ä»¶æ¸…å–®
```

=========================================================================================
ğŸš€ **ç’°å¢ƒå»ºç½® (Windows é–‹ç™¼ç’°å¢ƒ)**  
â€»å¦‚æœä½ æ˜¯ç¬¬ä¸€æ¬¡åœ¨ Windows ä¸ŠåŸ·è¡ŒCursorã€Pythonã€Dockerï¼Œè«‹ä¾ç…§ä»¥ä¸‹æ­¥é©Ÿè¨­å®šç’°å¢ƒã€‚  

**ç¬¬ 0 éšæ®µï¼šå®‰è£ç·¨è¼¯å™¨ (Cursorã€Dockerã€Python)**  
1.ä¸‹è¼‰ Cursor ä½œç‚ºç¨‹å¼ç¢¼ç·¨è¼¯å™¨  
  å‰å¾€ Cursor å®˜ç¶²ï¼Œä¸‹è¼‰å®‰è£æª”ã€‚  
  åŸ·è¡Œå®‰è£ç¨‹å¼ï¼Œä¸¦ä¾ç…§æŒ‡ç¤ºå®Œæˆå®‰è£ã€‚  

2.ä¸‹è¼‰Docker  
  å‰å¾€ Docker å®˜ç¶²ï¼Œä¸‹è¼‰å®‰è£æª”ã€‚  
  åŸ·è¡Œå®‰è£ç¨‹å¼ï¼Œä¸¦ä¾ç…§æŒ‡ç¤ºå®Œæˆå®‰è£ã€‚  

3.é–‹å•Ÿ Cursor çš„çµ‚ç«¯æ©Ÿï¼Œæª¢æŸ¥pythonæ˜¯å¦å·²å®‰è£  
  ```bash
  python --version æˆ– py --version æˆ– python3 --version  
  ```

4.ä¸‹è¼‰èˆ‡å®‰è£python  
  a.å‰å¾€ Python å®˜ç¶²ä¸‹è¼‰é é¢ã€‚  
  b.é»æ“Šé»ƒè‰²æŒ‰éˆ• Download Python 3.9ã€‚  
    â€»åŸ·è¡Œä¸‹è¼‰çš„å®‰è£æª” (âš ï¸ é‡è¦)  
    å‹™å¿…å‹¾é¸æœ€ä¸‹æ–¹çš„ â˜‘ï¸ Add Python.exe to PATH (å°‡ Python åŠ å…¥ç’°å¢ƒè®Šæ•¸)ã€‚  
  c.é»é¸ Install Now å®Œæˆå®‰è£ã€‚  

5.æ‰“é–‹ Cursor  
  é»æ“Šå·¦å´é‚Šæ¬„çš„ã€Œæ–¹å¡Šåœ–ç¤ºã€ (Extensions)ã€‚  
  æœå°‹ Pythonã€‚  
  æ‰¾åˆ°ç”± Microsoft é–‹ç™¼çš„é‚£å€‹ï¼ˆé€šå¸¸ä¸‹è¼‰é‡æœ€é«˜ï¼‰ï¼Œé»æ“Š Installã€‚ (é€™å€‹å¥—ä»¶æœƒå¹«ä½ åšèªæ³•é«˜äº®ã€ç¨‹å¼ç¢¼è£œå…¨ã€é‚„èƒ½å¹«ä½ é¸è™›æ“¬ç’°å¢ƒ)  

6.å®‰è£å®Œæˆå¾Œå›åˆ°æ­¥é©Ÿ1ï¼Œæª¢æŸ¥æ˜¯å¦å®‰è£æˆåŠŸï¼Œå®‰è£æˆåŠŸå¾Œï¼Œæ¥çºŒ7.é–‹å•Ÿå°ˆæ¡ˆè³‡æ–™å¤¾ã€‚  

7.é–‹å•Ÿå°ˆæ¡ˆè³‡æ–™å¤¾  
  åœ¨é›»è…¦æ¡Œé¢æˆ–ä½ ç¿’æ…£çš„åœ°æ–¹ï¼Œå»ºç«‹ä¸€å€‹æ–°è³‡æ–™å¤¾ï¼Œå‘½åç‚º 
  ```bash
  asus-news
  ```
  ã€‚  
  åœ¨ Cursor ä¸­ï¼Œé»é¸ 
  ```bash
  File -> Open Folder
  ```
  ï¼Œé¸æ“‡é€™å€‹è³‡æ–™å¤¾ã€‚  

------------------------------------------------------------------------------------------------
**ç¬¬ 1 éšæ®µï¼šå»ºç«‹è™›æ“¬ç’°å¢ƒ (Virtual Environment)** - ç‚ºé¿å…å½±éŸ¿é›»è…¦å…¶ä»–å°ˆæ¡ˆï¼Œéœ€è¦å»ºç«‹ä¸€å€‹ç¨ç«‹çš„ç’°å¢ƒã€‚  
1.é–‹å•Ÿ Cursor çš„çµ‚ç«¯æ©Ÿ  
  ä½¿ç”¨å¿«æ·éµ 
  ```bash
  Ctrl + ` 
  ```
  é–‹å•Ÿçµ‚ç«¯æ©Ÿã€‚  
  ç¢ºä¿çµ‚ç«¯æ©Ÿè·¯å¾‘æ˜¯åœ¨é€™å€‹å°ˆæ¡ˆçš„è³‡æ–™å¤¾åº•ä¸‹ã€‚  

2.è«‹ä¾åºè¼¸å…¥ä»¥ä¸‹æŒ‡ä»¤ï¼š  
  Windows:  
  (1). å»ºç«‹è™›æ“¬ç’°å¢ƒ (åªéœ€åšä¸€æ¬¡)  
       ```bash
       python -m venv .venv  
       ```

  (2). å•Ÿå‹•è™›æ“¬ç’°å¢ƒ (æ¯æ¬¡é‡é–‹ Cursor éƒ½è¦ç¢ºèªå‰é¢æœ‰ (.venv) å­—æ¨£ï¼Œé€šå¸¸ Cursor æœƒè‡ªå‹•åµæ¸¬)  
       ```bash
       .venv\Scripts\activate  
       ```

è¨»:  
Q:å¦‚æœé‡åˆ°.venv\Scripts\activateéŒ¯èª¤ç‚ºWindows PowerShell å®‰å…¨æ€§é™åˆ¶å•é¡Œ  
A:è§£æ±ºæ–¹æ³•  
  æ­¥é©Ÿ 1ï¼šä¿®æ”¹åŸ·è¡Œæ¬Šé™  
  ```bash
  Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser  
  ```
  æ­¥é©Ÿ 2ï¼šæ¬Šé™æ”¹å¥½å¾Œï¼Œå†åŸ·è¡Œä¸€æ¬¡åŸæœ¬çš„æŒ‡ä»¤  
ğŸ’¡å¦‚ä½•ç¢ºèªæˆåŠŸï¼Ÿ çœ‹åˆ° Terminal çš„æœ€å‰é¢å‡ºç¾äº†ç¶ è‰²æˆ–ç™½è‰²çš„ (.venv) å­—æ¨£  

------------------------------------------------------------------------------------------------
**ç¬¬ 2 éšæ®µï¼šé©—è­‰èˆ‡å®‰è£ä¾è³´**  
```bash
1.åœ¨ Cursor å·¦å´æª”æ¡ˆç¸½ç®¡æŒ‰å³éµ -> New File -> å‘½åç‚º requirements.txtã€‚  
```
2.è²¼ä¸Šä»¥ä¸‹å…§å®¹:  
  ```text
  requests>=2.31.0
  beautifulsoup4>=4.12.0
  selenium>=4.16.0
  webdriver-manager>=4.0.1
  mysql-connector-python>=8.2.0
  python-dotenv>=1.0.0
  pandas>=2.1.0
  ```

3.å›åˆ°çµ‚ç«¯æ©Ÿï¼Œè¼¸å…¥å®‰è£æŒ‡ä»¤ï¼š  
  ```bash
  pip install -r requirements.txt
```

------------------------------------------------------------------------------------------------
**ç¬¬ 3 éšæ®µï¼šDocker åŒ–**  
åœ¨ Docker ç’°å¢ƒä¸­ï¼Œæˆ‘å€‘æœƒå®šç¾©å…©å€‹ä¸»è¦çš„ Serviceï¼š  
db: MySQL 8.0 è³‡æ–™åº«ã€‚  
app: ä¹‹å¾Œè¦è·‘ Python çˆ¬èŸ²çš„å®¹å™¨ (ç›®å‰æˆ‘å€‘å…ˆé ç•™è¨­å®šï¼Œé‡é»å…ˆè®“ DB è·‘èµ·ä¾†)ã€‚  

1.å»ºç«‹è³‡æ–™åº«åˆå§‹åŒ–è…³æœ¬ (init.sql)  
  (1)åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„å»ºç«‹ä¸€å€‹è³‡æ–™å¤¾ï¼Œå‘½åç‚º dbã€‚  

  (2)åœ¨ db è³‡æ–™å¤¾å…§å»ºç«‹ä¸€å€‹æª”æ¡ˆ init.sqlã€‚  

  (3)è²¼ä¸Šä»¥ä¸‹ SQL ç¢¼(2å€‹TABLE)ï¼š    
    -- db/init.sql

    -- 1. å»ºç«‹ä¸¦ä½¿ç”¨è³‡æ–™åº«
    CREATE DATABASE IF NOT EXISTS security_news;
    USE security_news;

    -- 2. å»ºç«‹æ–°èè³‡æ–™è¡¨
    CREATE TABLE IF NOT EXISTS news (
        id INT AUTO_INCREMENT PRIMARY KEY,
        title NVARCHAR(255) NOT NULL,
        publish_date DATE NOT NULL,
        url NVARCHAR(2048) NOT NULL,
        source NVARCHAR(100),
        
        -- æ–°å¢: æ–°èæ‘˜è¦ (å°æ‡‰çˆ¬èŸ²çš„ description)
        description TEXT,
        
        -- æµç¨‹åœ–é‚è¼¯æ ¸å¿ƒæ¬„ä½:
        -- status: 'N'=æ–°è³‡æ–™(New), 'Y'=å·²å¡«è¡¨(Yes), 'E'=éŒ¯èª¤(Error)
        status CHAR(1) DEFAULT 'N' NOT NULL,
        
        -- fail_count: ç´€éŒ„å¡«è¡¨å¤±æ•—æ¬¡æ•¸ (æµç¨‹åœ–: å¤±æ•—è¶…é3æ¬¡ -> E)
        fail_count INT DEFAULT 0,
        
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        -- å»é‡æ©Ÿåˆ¶: åŒä¸€å¤©ã€åŒæ¨™é¡Œçš„æ–°èè¦–ç‚ºé‡è¤‡ï¼Œæ‹’çµ•å¯«å…¥
        UNIQUE KEY unique_news_check (title, publish_date)
    ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;

    ğŸ“Š è³‡æ–™åº« news_Schema
    æ¬„ä½	        é¡å‹	    èªªæ˜
    id	            INT	        Primary Key
    title	        NVARCHAR    æ–°èæ¨™é¡Œ
    url	            NVARCHAR	åŸå§‹é€£çµ
    publish_date	DATE	    ç™¼å¸ƒæ—¥æœŸ (æ¨™æº–åŒ– YYYY-MM-DD)
    source	        NVARCHAR    ä¾†æºåˆ†é¡ (å¦‚: Google News (TW))
    description	    TEXT	    å…§æ–‡æ‘˜è¦ (å„ªå…ˆä½¿ç”¨å…§æ–‡ï¼Œå‚™ç”¨ Google Snippet)
    status	        CHAR(1)	    N(æ–°), Y(å®Œ), E(éŒ¯)
    fail_count	    INT	        å¤±æ•—é‡è©¦æ¬¡æ•¸
    created_at	    TIMESTAMP	æ“·å–æ™‚é–“ (UTCï¼Œå¡«è¡¨æ™‚æœƒè‡ªå‹•è½‰ +8)

  (4)å»ºç«‹ docker-compose.yml  
    ```text
    version: '3.8'
    services:
    # 1. MySQL è³‡æ–™åº«æœå‹™
    mysql-db:
        image: mysql:8.0
        container_name: asus_news_db
        restart: always
        environment:
        MYSQL_ROOT_PASSWORD: mysecretpassword
        MYSQL_DATABASE: security_news
        MYSQL_USER: scraper_user
        MYSQL_PASSWORD: scraper_password
        # --- [æ–°å¢é€™è¡Œ] å¼·åˆ¶ä¼ºæœå™¨ç«¯ä½¿ç”¨ UTF-8 ç·¨ç¢¼ ---
        command: --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci
        # ---------------------------------------------
        ports:
        - "3306:3306"
        volumes:
        - db_data:/var/lib/mysql
        - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql
        networks:
        - scraper_network
        healthcheck:
        test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
        interval: 10s
        timeout: 5s
        retries: 5

    # 2. Python æ‡‰ç”¨ç¨‹å¼æœå‹™
    app:
        build: .
        container_name: asus_news_worker
        depends_on:
        mysql-db:
            condition: service_healthy
        # --- [é—œéµä¿®æ­£] ---
        # ä½¿ç”¨ env_file ç›´æ¥è¼‰å…¥ .env æª”æ¡ˆä¸­çš„æ‰€æœ‰è®Šæ•¸
        # é€™æ¨£ Python æ‰èƒ½è®€å–åˆ° GOOGLE_FORM_URL
        env_file:
        - .env
        # ----------------
        volumes:
        - .:/app
        networks:
        - scraper_network
        # ä¿æŒå®¹å™¨é–‹å•Ÿï¼Œæ–¹ä¾¿é–‹ç™¼
        # åŸæœ¬æ˜¯: command: tail -f /dev/null
        command: python app/main.py

    volumes:
    db_data:

    networks:
    scraper_network:
        driver: bridge
    ```

  (5)å»ºç«‹ Dockerfile (docker-compose.yml è£¡é¢åƒç…§äº† build: .ï¼Œéœ€è¦ä¸€å€‹ Dockerfile æ‰èƒ½è·‘)  
     a.åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„å»ºç«‹ Dockerfileã€‚  
     b.åœ¨Dockerfileè²¼ä¸Šä»¥ä¸‹å…§å®¹ï¼š  
        # ä½¿ç”¨ Python 3.9 Slim
        FROM python:3.9-slim

        # è¨­å®šç’°å¢ƒè®Šæ•¸
        ENV PYTHONDONTWRITEBYTECODE=1
        ENV PYTHONUNBUFFERED=1

        # è¨­å®šå·¥ä½œç›®éŒ„
        WORKDIR /app

        # 1. å®‰è£ç³»çµ±ä¾è³´
        # æˆ‘å€‘éœ€è¦ gnupg ä¾†è™•ç†é‡‘é‘°
        RUN apt-get update && apt-get install -y \
            wget \
            gnupg \
            unzip \
            curl \
            # Chrome åŸ·è¡Œæ‰€éœ€ä¾è³´ (Debian 12/13 é©ç”¨)
            libnss3 \
            libxss1 \
            libasound2 \
            fonts-liberation \
            libnspr4 \
            xdg-utils \
            libgbm1 \
            libu2f-udev \
            libvulkan1 \
            && rm -rf /var/lib/apt/lists/*

        # 2. å®‰è£ Google Chrome (ä½¿ç”¨æ–°ç‰ˆ signed-by æ©Ÿåˆ¶ï¼Œä¸ä½¿ç”¨ apt-key)
        RUN wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | \
            gpg --dearmor -o /usr/share/keyrings/google-chrome-keyring.gpg \
            && echo "deb [arch=amd64 signed-by=/usr/share/keyrings/google-chrome-keyring.gpg] http://dl.google.com/linux/chrome/deb/ stable main" \
            > /etc/apt/sources.list.d/google-chrome.list \
            && apt-get update \
            && apt-get install -y google-chrome-stable

        # 3. å®‰è£ Python å¥—ä»¶
        COPY requirements.txt .
        RUN pip install --no-cache-dir -r requirements.txt

        # 4. è¤‡è£½ç¨‹å¼ç¢¼
        COPY . .

        # 5. é è¨­æŒ‡ä»¤
        CMD ["tail", "-f", "/dev/null"]
     
     c.åœ¨.envè²¼ä¸Šä»¥ä¸‹å…§å®¹ï¼Œåšç’°å¢ƒè¨­å®š  
        # --- è³‡æ–™åº«é€£ç·šè¨­å®š (å¿…é ˆèˆ‡ docker-compose.yml ä¸€è‡´) ---
        # æ³¨æ„: åœ¨ Docker å…§éƒ¨äº’é€£æ™‚ï¼ŒHOST å¿…é ˆæ˜¯ docker-compose è£¡çš„ service name (mysql-db)
        # è‹¥æ˜¯å¾æœ¬æ©ŸåŸ·è¡Œ python (é Docker)ï¼Œå‰‡éœ€æ”¹ç‚º localhost
        DB_HOST=mysql-db
        DB_PORT=3306
        DB_USER=scraper_user
        DB_PASSWORD=scraper_password
        DB_NAME=security_news

        # --- Google è¡¨å–®è¨­å®š ---
        # è«‹å°‡æ­¤ç¶²å€æ›¿æ›ç‚ºæ‚¨å¯¦éš›è¦è‡ªå‹•å¡«å¯«çš„ Google Form ç¶²å€
        GOOGLE_FORM_URL=https://docs.google.com/forms/d/e/1FAIpQLScUld1s4B_RNVnCqSmK_dzgC7fS0cNrZZxAAIrwmyGZdqS7Yg/viewform?usp=publish-editor

        # --- é–‹ç™¼ç’°å¢ƒè¨­å®š ---
        # è§£æ±º Cursor/VSCode æ‰¾ä¸åˆ°æ¨¡çµ„ (reportMissingImports) çš„å•é¡Œ
        # è®“ Python çŸ¥é“ app è³‡æ–™å¤¾ä¹Ÿæ˜¯æ¨¡çµ„ä¾†æº
        PYTHONPATH=app

     d.å•Ÿå‹• Docker Desktop  

     e.æ‰“é–‹çµ‚ç«¯æ©Ÿï¼Œé‡è¨­é€£ç·š  
       ```bash
       docker context use default
       ```

     f.æ‰“é–‹çµ‚ç«¯æ©Ÿï¼Œå˜—è©¦é€£ç·š  
       ```bash
       docker ps
       ```

     g.æ‰“é–‹çµ‚ç«¯æ©Ÿï¼ŒåŸ·è¡Œæœƒè‡ªå‹•å»ºç½®åŒ…å« Chrome çš„ Python ç’°å¢ƒä»¥åŠåˆå§‹åŒ– MySQL è³‡æ–™åº«  
       ```bash
       docker-compose up -d --build
       ```

     h.æ‰“é–‹çµ‚ç«¯æ©Ÿï¼ŒæŸ¥çœ‹ç¾åœ¨çš„ç‹€æ…‹  
       ```bash
       docker ps
       ```
       ```text
       æƒ…æ³ Aï¼šçœ‹åˆ°ç©ºè•©è•©çš„æ¨™é¡Œï¼Œæˆ–æ˜¯ä»€éº¼éƒ½æ²’æœ‰  
       CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS   PORTS   NAMES
       
       æƒ…æ³ Bï¼šçœ‹åˆ°å…©è¡Œè³‡æ–™ (mysql å’Œ python)ï¼Œä¾‹å¦‚:  
       CONTAINER ID   IMAGE              ...   STATUS          NAMES
       abc12345       mysql:8.0          ...   Up 5 seconds    asus_news_db
       def67890       asus-news-app      ...   Up 5 seconds    asus_news_worker

       â€»å¦‚æœæœ‰æƒ…æ³Aï¼Œå¯èƒ½æ˜¯Dockerfileä¸­çš„ä¾è³´æˆ–é©—è­‰ç‰ˆæœ¬å•é¡Œï¼Œå°‡Dockerfileé‡æ–°ç¢ºèªå¾Œï¼Œå†é‡æ–°åš  
         å¼·åˆ¶é‡æ–°ä¸‹è¼‰æ‰€æœ‰çš„ Chrome å’Œä¾è³´å¥—ä»¶ï¼Œç¢ºä¿ä½ çš„æ–° Dockerfile é‚è¼¯è¢«çœŸæ­£åŸ·è¡Œã€‚  
         docker-compose build --no-cache
         å»ºç½®æˆåŠŸå¾Œï¼ˆæ²’æœ‰å ±éŒ¯ï¼‰ï¼Œå†å•Ÿå‹•å®ƒ  
         docker-compose up -d --force-recreate
       ```
**=========================================================================================**
ğŸš€ **æ’°å¯«çˆ¬èŸ²ç¨‹å¼å»ºç½® (Windows é–‹ç™¼ç’°å¢ƒ)**  

**ç¬¬ 1 éšæ®µï¼šå»ºç«‹å°ˆæ¡ˆçµæ§‹**  
1.åœ¨æ ¹ç›®éŒ„ä¸‹å»ºç«‹app è³‡æ–™å¤¾  

2.åœ¨appè³‡æ–™å¤¾ä¸‹ï¼Œå»ºç«‹ä»¥ä¸‹æª”æ¡ˆ  
  ```text
    asus-news/
    â”œâ”€â”€ app/                    # æ ¸å¿ƒæ‡‰ç”¨ç¨‹å¼é‚è¼¯
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ main.py             # ç¨‹å¼é€²å…¥é» (Entry Point)
    â”‚   â”œâ”€â”€ scraper.py          # çˆ¬èŸ²é‚è¼¯ (Requests/BS4)
    â”‚   â”œâ”€â”€ utils.py            # å·¥å…·åŒ…
    â”‚   â”œâ”€â”€ database.py         # è³‡æ–™åº«æ“ä½œ (MySQL é€£ç·šèˆ‡ CRUD)
    â”‚   â”œâ”€â”€ form_filler.py      # è‡ªå‹•å¡«è¡¨é‚è¼¯ (Selenium)
    â”‚â”€â”€ â””â”€â”€ logger.py           # æ—¥èªŒè¨­å®š (Logging)
  ```
------------------------------------------------------------------------------------------------
**ç¬¬ 2 éšæ®µï¼šæ’°å¯«ç¨‹å¼ç¢¼**  

âš™ï¸ ç¨‹å¼ç¢¼æ ¸å¿ƒé‚è¼¯èªªæ˜  
```text
Phase 1: çˆ¬èŸ²èˆ‡è³‡æ–™æ¸…æ´—  
å¤šæºæ’ç¨‹ï¼šç³»çµ±ä¾åºåŸ·è¡Œä»¥ä¸‹æœå°‹ä»»å‹™ï¼š  
Google News (EN): é‡å°åœ‹éš›è³‡å®‰æ–°èã€‚  
Google News (TW): é‡å°å°ç£åœ¨åœ°å ±å°ã€‚  
å®˜æ–¹è³‡æº: é‡å° site:asus.comã€‚  
è³‡å®‰é€šå ±: é‡å° bleepingcomputer ç­‰æ¬Šå¨ç¶²ç«™ã€‚  
æ·±åº¦é–±è®€ï¼šé€²å…¥æ–°èé é¢æŠ“å–å…§æ–‡ã€‚è‹¥é‡åˆ° 404 æˆ– PDFï¼Œæœƒè‡ªå‹•æ¨™è¨˜ä¸¦è·³éæˆ–ä½¿ç”¨å‚™ç”¨æ‘˜è¦ã€‚  
éæ¿¾æ©Ÿåˆ¶ï¼šæª¢æŸ¥æ¨™é¡Œèˆ‡å…§æ–‡æ˜¯å¦åŒ…å« ASUS ä¸”åŒæ™‚åŒ…å« Router æˆ– Security ç›¸é—œé—œéµå­— (æ”¯æ´ä¸­è‹±)ã€‚  
å»é‡å…¥åº«ï¼šä½¿ç”¨ INSERT IGNORE èˆ‡ Unique Key (Title + Date) é˜²æ­¢é‡è¤‡è³‡æ–™å¯«å…¥ MySQLã€‚  

Phase 2: è‡ªå‹•å¡«è¡¨  
ç‹€æ…‹è®€å–ï¼šå¾è³‡æ–™åº«æ’ˆå–ç‹€æ…‹ç‚º N (New) çš„è³‡æ–™ã€‚  
æ™‚å€æ ¡æ­£ï¼šå°‡è³‡æ–™åº«çš„ UTC æ™‚é–“è½‰æ›ç‚ºå°ç£æ™‚é–“ (UTC+8)ã€‚  
æ™ºæ…§å¡«å¯«ï¼šä½¿ç”¨ JavaScript ç›´æ¥å° DOM å…ƒç´ è³¦å€¼ï¼Œç¹é Selenium send_keys å¯èƒ½å¤±æ•—çš„é™åˆ¶ã€‚  
ç‹€æ…‹æ›´æ–°ï¼šå¡«å¯«æˆåŠŸå¾Œå°‡ç‹€æ…‹æ›´æ–°ç‚º Yï¼Œå¤±æ•—è¶…é 3 æ¬¡å‰‡æ¨™è¨˜ç‚º Eã€‚  
```

1.è«‹å°‡ä»¥ä¸‹å…§å®¹è¤‡è£½åˆ° app/scraper.py  
```text
    import logging
    import time
    import random
    import re
    from typing import List, Dict, Optional
    from selenium import webdriver
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, WebDriverException
    from urllib3.exceptions import MaxRetryError, NewConnectionError
    from webdriver_manager.chrome import ChromeDriverManager
    from logger import logger

    class NewsScraper:
        def __init__(self):
            self.driver = None
            self._init_driver()

        def _init_driver(self):
            """åˆå§‹åŒ–æˆ–é‡å•Ÿ Driver"""
            if self.driver:
                try: self.driver.quit()
                except: pass
            
            logger.info("å•Ÿå‹• Chrome Driver (V14 Final)...")
            self.driver = self._setup_driver()

        def _setup_driver(self) -> webdriver.Chrome:
            chrome_options = Options()
            chrome_options.add_argument("--headless=new") 
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            
            # [é—œéµå„ªåŒ–] Eager æ¨¡å¼ï¼šHTML ä¸‹è¼‰å®Œå°±ä¸ç­‰åœ–ç‰‡/å»£å‘Š
            chrome_options.page_load_strategy = 'eager'
            
            # è¨˜æ†¶é«”å„ªåŒ–
            chrome_options.add_argument("--blink-settings=imagesEnabled=false") 
            chrome_options.add_argument("--disable-gpu")
            chrome_options.add_argument("--disable-extensions")
            chrome_options.add_argument("--window-size=1920,1080")
            
            # åçˆ¬èŸ²å½è£
            chrome_options.add_argument("--disable-blink-features=AutomationControlled")
            chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36")

            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=chrome_options)
            
            # è¨­å®šè¼ƒçŸ­çš„è¶…æ™‚ï¼Œé¿å…å¡æ­»
            driver.set_page_load_timeout(20)
            driver.set_script_timeout(20)
            
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            return driver

        def close(self):
            try:
                if self.driver:
                    self.driver.quit()
                    logger.info("çˆ¬èŸ²å·²çµæŸä¸¦é—œé–‰")
            except:
                pass

        def is_relevant(self, title: str, content: str = "") -> bool:
            """ä¸­è‹±æ–‡é—œéµå­—éæ¿¾"""
            text_to_check = (title + " " + content).lower()
            if "asus" not in text_to_check and "è¯ç¢©" not in text_to_check:
                return False
            
            router_keywords = ["router", "rt-", "gt-", "zenwifi", "aimesh", "tuf gaming", "rog rapture", "è·¯ç”±å™¨", "åˆ†äº«å™¨", "ç¶²é€š", "wifi"]
            security_keywords = ["security", "vulnerability", "cve", "exploit", "hack", "patch", "firmware", "backdoor", "botnet", "malware", "cyber", "attack", "warn", "alert", "risk", "è³‡å®‰", "æ¼æ´", "é§­å®¢", "æ”»æ“Š", "æ›´æ–°", "ä¿®è£œ", "éŸŒé«”", "å¾Œé–€", "æƒ¡æ„", "æ®­å±", "å®‰å…¨", "é¢¨éšª"]
            
            has_router = any(kw in text_to_check for kw in router_keywords)
            has_security = any(kw in text_to_check for kw in security_keywords)
            
            return has_router or has_security

        def read_article_content(self, url: str) -> str:
            if url.lower().endswith('.pdf'): return "SKIP_PDF"
            
            # æœ€å¤šé‡è©¦ 1 æ¬¡ (é‡åˆ° Driver æ­»æ‰æ™‚é‡å•Ÿ)
            for attempt in range(2):
                try:
                    if not self.driver: self._init_driver()

                    logger.info(f"æ­£åœ¨é–±è®€å…§æ–‡: {url[:50]}...")
                    
                    try:
                        self.driver.get(url)
                    except TimeoutException:
                        try: self.driver.execute_script("window.stop();")
                        except: pass
                    
                    time.sleep(random.uniform(1.0, 2.0))

                    # --- [é—œéµä¿®æ­£] éŒ¯èª¤é é¢æª¢æ¸¬ ---
                    try:
                        page_title = self.driver.title.lower()
                        # 1. æ“´å……éŒ¯èª¤é—œéµå­—æ¸…å–®
                        error_keywords = [
                            "404", "not found", "page not found", "æ‰¾ä¸åˆ°ç¶²é ", "ç„¡æ³•é¡¯ç¤ºç¶²é ", 
                            "article not found", "error 404", "sorry", "access denied", 
                            "forbidden", "è®€å–å¤±æ•—", "ç„¡æ³•è¼‰å…¥", "site can't be reached", 
                            "refused to connect", "bad gateway", "service unavailable"
                        ]
                        
                        # 2. æª¢æŸ¥æ¨™é¡Œ
                        if any(kw in page_title for kw in error_keywords):
                            logger.warning(f"åµæ¸¬åˆ°éŒ¯èª¤æ¨™é¡Œ ({page_title})ï¼Œç«‹å³è·³é: {url}")
                            return "SKIP_ERROR"
                        
                        # 3. æª¢æŸ¥é é¢å…§å®¹é–‹é ­
                        body_elem = self.driver.find_element(By.TAG_NAME, "body")
                        body_start = body_elem.text[:500].lower()
                        
                        if any(kw in body_start for kw in error_keywords):
                            logger.warning(f"åµæ¸¬åˆ°éŒ¯èª¤å…§å®¹ (å¦‚ 404/Sorry)ï¼Œç«‹å³è·³é: {url}")
                            return "SKIP_ERROR"
                    except:
                        pass
                    # -------------------------------------

                    paragraphs = self.driver.find_elements(By.TAG_NAME, "p")
                    content = [p.text.strip() for p in paragraphs if len(p.text.strip()) > 30]
                    if content: return " ".join(content)[:300] + "..."

                    try:
                        body = self.driver.find_element(By.TAG_NAME, "body")
                        clean_text = " ".join(body.text.split())
                        if len(clean_text) > 50: return clean_text[:300] + "..."
                    except: pass
                    
                    return "ç„¡æ³•æå–æœ‰æ•ˆæ–‡å­—"

                except Exception as e:
                    error_msg = str(e)
                    if "HTTPConnectionPool" in error_msg or "refused" in error_msg or "invalid session" in error_msg:
                        logger.warning(f"åµæ¸¬åˆ°ç€è¦½å™¨å´©æ½°ï¼Œæ­£åœ¨é‡å•Ÿ Driver...")
                        self._init_driver()
                        time.sleep(2)
                        continue 
                    
                    logger.warning(f"é–±è®€å¤±æ•—: {error_msg[:50]}")
                    return "SKIP_ERROR" # ç™¼ç”Ÿç•°å¸¸ä¹Ÿç›´æ¥è·³éï¼Œä¸è¦å­˜
            
            return "SKIP_ERROR"

        def scrape_google_search(self, query: str, source_category: str, search_type: str = 'news', lang: str = 'en') -> List[Dict]:
            results = []
            try:
                if not self.driver: self._init_driver()

                base_url = "https://www.google.com/search?q={}&hl={}"
                
                if search_type == 'news':
                    url = base_url.format(query, lang) + "&tbm=nws&tbs=qdr:m6"
                else:
                    url = base_url.format(query, lang) + "&tbs=qdr:y"

                logger.info(f"[{source_category} | {lang}] å‰å¾€æœå°‹: {url}")
                
                try:
                    self.driver.get(url)
                except:
                    try: self.driver.execute_script("window.stop();")
                    except: pass

                time.sleep(3)

                for _ in range(2):
                    try:
                        self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                        time.sleep(2)
                    except: 
                        self._init_driver()
                        break

                try:
                    WebDriverWait(self.driver, 10).until(EC.presence_of_element_located((By.ID, "search")))
                except: pass

                if search_type == 'news':
                    items = self.driver.find_elements(By.CSS_SELECTOR, "div.SoaBEf")
                    if not items: items = self.driver.find_elements(By.CSS_SELECTOR, "div.MjjYud")
                else:
                    items = self.driver.find_elements(By.CSS_SELECTOR, "div.g")

                logger.info(f"[{source_category}] æ‰¾åˆ° {len(items)} ç­†åŸå§‹è³‡æ–™")

                valid_count = 0
                for item in items:
                    try:
                        if search_type == 'news':
                            title_elem = item.find_element(By.CSS_SELECTOR, "div[role='heading']")
                        else:
                            title_elem = item.find_element(By.TAG_NAME, "h3")
                        
                        link_elem = item.find_element(By.TAG_NAME, "a")
                        link = link_elem.get_attribute("href")
                        title = title_elem.text

                        snippet = ""
                        try:
                            desc_elem = item.find_element(By.CSS_SELECTOR, ".GI74Re, .VwiC3b")
                            snippet = desc_elem.text
                        except: pass

                        if not self.is_relevant(title, snippet):
                            continue

                        date_str = "Today"
                        try:
                            date_elem = item.find_element(By.CSS_SELECTOR, ".OSrXXb span, .MUxGbd, .LEwnzc span") 
                            date_str = date_elem.text
                        except: pass

                        results.append({
                            "title": title,
                            "url": link,
                            "date_raw": date_str,
                            "source": source_category,
                            "description": snippet
                        })
                        valid_count += 1
                    except:
                        continue
                
                logger.info(f"[{source_category}] ä¿ç•™ {valid_count} ç­†æœ‰æ•ˆè³‡æ–™")

            except Exception as e:
                logger.error(f"[{source_category}] æœå°‹éŒ¯èª¤: {e}")
                self._init_driver()
            
            return results
```
2.è«‹å°‡ä»¥ä¸‹å…§å®¹è¤‡è£½åˆ° app/utils.pyï¼Œå»ºç«‹æ—¥æœŸè™•ç†å·¥å…·  
```text
    import re
    from datetime import datetime, timedelta

    def parse_relative_date(date_str: str) -> str:
        """
        å°‡ Google News çš„æ™‚é–“å­—ä¸² (æ”¯æ´è‹±æ–‡èˆ‡ä¸­æ–‡æ ¼å¼) 
        è½‰æ›ç‚ºæ¨™æº–æ—¥æœŸæ ¼å¼ (YYYY-MM-DD)ã€‚
        """
        today = datetime.now()
        date_str = date_str.strip()
        
        try:
            # --- è‹±æ–‡æ ¼å¼è™•ç† (English) ---
            
            # è™•ç† "3 days ago", "5 mins ago", "2 weeks ago"
            if 'ago' in date_str.lower():
                # æå–æ•¸å­—
                num_match = re.search(r'(\d+)', date_str)
                number = int(num_match.group(1)) if num_match else 0
                
                if 'min' in date_str or 'hour' in date_str:
                    return today.strftime("%Y-%m-%d")
                elif 'day' in date_str:
                    dt = today - timedelta(days=number)
                    return dt.strftime("%Y-%m-%d")
                elif 'week' in date_str:
                    dt = today - timedelta(weeks=number)
                    return dt.strftime("%Y-%m-%d")
                elif 'month' in date_str:
                    dt = today - timedelta(days=number*30)
                    return dt.strftime("%Y-%m-%d")

            # è™•ç† "Yesterday"
            if 'Yesterday' in date_str:
                dt = today - timedelta(days=1)
                return dt.strftime("%Y-%m-%d")

            # è™•ç†çµ•å°æ—¥æœŸ "Jul 19, 2025", "July 19, 2025", "19 July 2025"
            # å˜—è©¦å¤šç¨®è‹±æ–‡æ—¥æœŸæ ¼å¼
            for fmt in ["%b %d, %Y", "%B %d, %Y", "%d %b %Y", "%d %B %Y"]:
                try:
                    dt = datetime.strptime(date_str, fmt)
                    return dt.strftime("%Y-%m-%d")
                except ValueError:
                    continue

            # --- ä¸­æ–‡æ ¼å¼è™•ç† (Chinese) ---
            
            if "å¹´" in date_str and "æœˆ" in date_str:
                dt = datetime.strptime(date_str, "%Yå¹´%mæœˆ%dæ—¥")
                return dt.strftime("%Y-%m-%d")

            days_match = re.search(r'(\d+)\s*å¤©å‰', date_str)
            if days_match:
                days = int(days_match.group(1))
                dt = today - timedelta(days=days)
                return dt.strftime("%Y-%m-%d")

            weeks_match = re.search(r'(\d+)\s*é€±å‰', date_str)
            if weeks_match:
                weeks = int(weeks_match.group(1))
                dt = today - timedelta(weeks=weeks)
                return dt.strftime("%Y-%m-%d")
                
            if "æ˜¨å¤©" in date_str:
                dt = today - timedelta(days=1)
                return dt.strftime("%Y-%m-%d")

            # è‹¥éƒ½ç„¡æ³•è§£æï¼Œå›å‚³ä»Šå¤© (ä½†ä¹Ÿå°å‡ºéŒ¯èª¤ä»¥ä¾¿é™¤éŒ¯)
            # print(f"Warning: ç„¡æ³•è§£ææ—¥æœŸ '{date_str}'ï¼Œé è¨­ç‚ºä»Šå¤©")
            return today.strftime("%Y-%m-%d")

        except Exception as e:
            print(f"æ—¥æœŸè§£æå¤±æ•—: {date_str}, éŒ¯èª¤: {e}")
            return today.strftime("%Y-%m-%d")
```

3.è«‹å°‡ä»¥ä¸‹å…§å®¹è¤‡è£½åˆ° app/main.pyï¼Œæ›´æ–°ä¸»ç¨‹å¼  
```text
    import logging
    import time
    import os
    import gc
    from datetime import datetime, timedelta, timezone
    from scraper import NewsScraper
    from database import Database
    from utils import parse_relative_date
    from form_filler import FormFiller
    from logger import logger

    # å¤šæºæœå°‹è¨­å®š
    SEARCH_CONFIGS = [
        {
            "category": "Google News (EN)",
            "query": "ASUS router security",
            "type": "news",
            "lang": "en"
        },
        {
            "category": "Google News (TW)",
            "query": "è¯ç¢© è·¯ç”±å™¨ è³‡å®‰",
            "type": "news",
            "lang": "zh-TW"
        },
        {
            "category": "å®˜æ–¹è³‡æº",
            "query": "site:asus.com security router",
            "type": "web",
            "lang": "en"
        },
        {
            "category": "è³‡å®‰é€šå ±", 
            "query": "site:bleepingcomputer.com OR site:thehackernews.com ASUS",
            "type": "news",
            "lang": "en"
        }
    ]

    def process_scraping_job():
        logger.info("=== éšæ®µä¸€: é›™èªå¤šæºçˆ¬èŸ²å•Ÿå‹• ===")
        scraper = NewsScraper()
        
        try:
            all_news_data = []
            
            for config in SEARCH_CONFIGS:
                logger.info(f"åŸ·è¡Œä»»å‹™: {config['category']}...")
                
                raw_data = scraper.scrape_google_search(
                    query=config['query'],
                    source_category=config['category'],
                    search_type=config['type'],
                    lang=config['lang'] 
                )
                
                all_news_data.extend(raw_data[:5])
                time.sleep(2)

            if not all_news_data:
                logger.warning("æœªæ‰¾åˆ°ä»»ä½•è³‡æ–™ã€‚")
                return

            logger.info(f"æœå°‹å®Œæˆï¼Œå…± {len(all_news_data)} ç­†ï¼Œé–‹å§‹é–±è®€å…§æ–‡...")
            
            cleaned_data = []
            tw_tz = timezone(timedelta(hours=8))
            capture_time = datetime.now(tw_tz).strftime('%Y-%m-%d %H:%M:%S')

            for item in all_news_data:
                deep_content = scraper.read_article_content(item['url'])
                
                if deep_content in ["SKIP_404", "SKIP_PDF", "SKIP_ERROR","drifted off-grid","Page Not Found!","SORRY","Sorry! Page not found"]:
                    logger.warning(f"è·³éç„¡æ•ˆ/éŒ¯èª¤é€£çµ: {item['title'][:20]}...")
                    continue
                
                final_desc = "ç„¡æ‘˜è¦"
                if deep_content and len(deep_content) > 30 and "å¤±æ•—" not in deep_content:
                    final_desc = deep_content
                elif item.get('description'):
                    final_desc = f"[Googleæ‘˜è¦] {item['description']}"
                
                std_date = parse_relative_date(item['date_raw'])
                
                cleaned_data.append({
                    'title': item['title'].strip(),
                    'url': item['url'],
                    'publish_date': std_date,
                    'source': item['source'],
                    'description': final_desc,
                    'captured_at': capture_time 
                })

            if cleaned_data:
                db = Database()
                new_count = db.insert_news(cleaned_data)
                logger.info(f"éšæ®µä¸€çµæŸã€‚è³‡æ–™åº«å¯¦éš›æ–°å¢: {new_count} ç­†ã€‚")
            else:
                logger.warning("éšæ®µä¸€çµæŸã€‚æ²’æœ‰æœ‰æ•ˆè³‡æ–™å¯å¯«å…¥ã€‚")
            
        except Exception as e:
            logger.error(f"çˆ¬èŸ²éšæ®µç™¼ç”ŸéŒ¯èª¤: {e}")
        finally:
            scraper.close()
            del scraper
            gc.collect()

    def process_form_filling_job():
        logger.info("=== éšæ®µäºŒ: å¡«å¯«è¡¨å–® (Status='N') ===")
        db = Database()
        pending_tasks = db.get_pending_news()
        
        # çµ±è¨ˆè®Šæ•¸
        total_tasks = 0
        success_count = 0
        fail_count = 0
        
        if not pending_tasks:
            logger.info("æ²’æœ‰å¾…è™•ç†è³‡æ–™ã€‚")
            return total_tasks, success_count, fail_count

        total_tasks = len(pending_tasks)
        logger.info(f"ç™¼ç¾ {total_tasks} ç­†ä»»å‹™ï¼Œå•Ÿå‹•å¡«è¡¨æ©Ÿå™¨äºº...")
        
        for i, task in enumerate(pending_tasks):
            news_id = task['id']
            title = task['title']
            logger.info(f"[{i+1}/{total_tasks}] å¡«å¯«ä¸­: {title[:15]}...")

            filler = None
            try:
                filler = FormFiller()
                is_success = filler.fill_form(task)
                
                if is_success:
                    db.update_status(news_id, 'Y')
                    logger.info(f"-> æˆåŠŸ (ID {news_id})")
                    success_count += 1
                else:
                    raise Exception("æäº¤å¤±æ•—")

            except Exception as e:
                logger.error(f"-> å¤±æ•— (ID {news_id}): {e}")
                db.record_failure(news_id)
                fail_count += 1
            finally:
                if filler:
                    try: filler.driver.quit()
                    except: pass
                del filler
                gc.collect()
                time.sleep(3)
                
        return total_tasks, success_count, fail_count

    def main():
        logger.info("=== ç³»çµ±å•Ÿå‹•ï¼šé€²å…¥è‡ªå‹•åŒ–æ’ç¨‹æ¨¡å¼ ===")
        # åŠ å…¥ while True è®“å®ƒè®Šæˆç„¡çª®è¿´åœˆ
        while True:
            try:
                time.sleep(2)
                process_scraping_job()
                gc.collect()
                time.sleep(2)
                
                # æ¥æ”¶å›å‚³çš„çµ±è¨ˆæ•¸æ“š
                total, success, fail = process_form_filling_job()
                
                logger.info("=== å…¨éƒ¨å®Œæˆ ===")
                # é¡¯ç¤ºçµ±è¨ˆçµæœ
                logger.info(f"åŸ·è¡Œçµ±è¨ˆ: ç¸½å…± {total} ç­† | æˆåŠŸ: {success} ç­† | å¤±æ•—: {fail} ç­†")
                
            except Exception as e:
                logger.critical(f"ä¸»ç¨‹å¼å´©æ½°: {e}")
                
            # è¨­å®šä¸‹æ¬¡åŸ·è¡Œçš„ç­‰å¾…æ™‚é–“ (ç›®å‰è¨­å®šç‚º 24 å°æ™‚ = 86400 ç§’)
            wait_seconds = 86400 
            logger.info(f"é€²å…¥å¾…æ©Ÿæ¨¡å¼ï¼Œ{wait_seconds/3600} å°æ™‚å¾Œå°‡å†æ¬¡åŸ·è¡Œ...")
            time.sleep(wait_seconds)

    if __name__ == "__main__":
        main()
```

4.è«‹å°‡ä»¥ä¸‹å…§å®¹è¤‡è£½åˆ° app/database.pyï¼Œæ›´æ–°è³‡æ–™åº«æ¨¡çµ„  
```text
    import mysql.connector
    import os
    import logging
    from typing import List, Dict, Optional
    from logger import logger

    # è¨­å®š logger
    # logger = logging.getLogger(__name__)

    class Database:
        def __init__(self):
            self.config = {
                'user': os.getenv('DB_USER', 'scraper_user'),
                'password': os.getenv('DB_PASSWORD', 'scraper_password'),
                'host': os.getenv('DB_HOST', 'mysql-db'),
                'database': os.getenv('DB_NAME', 'security_news'),
                'charset': 'utf8mb4',
                'collation': 'utf8mb4_unicode_ci',
                # ==========================================
                # é—œéµä¿®æ­£ï¼šå¿…é ˆè¨­ç‚º Falseï¼Œå¦å‰‡é‡è¤‡è³‡æ–™æœƒå°è‡´å…¨éƒ¨å›æ»¾
                # ==========================================
                'raise_on_warnings': False,  
                'autocommit': False 
            }

        def get_connection(self):
            """å»ºç«‹ä¸¦å›å‚³è³‡æ–™åº«é€£ç·š"""
            conn = mysql.connector.connect(**self.config)
            
            try:
                cursor = conn.cursor()
                cursor.execute("SET NAMES utf8mb4;")
                cursor.execute("SET CHARACTER SET utf8mb4;")
                cursor.execute("SET character_set_connection=utf8mb4;")
                cursor.close()
            except:
                pass
            # ==============================
            
            return conn

        def insert_news(self, news_list: List[Dict]) -> int:
            if not news_list:
                return 0

            inserted_count = 0
            conn = None
            cursor = None
            
            try:
                conn = self.get_connection()
                cursor = conn.cursor()

                sql = """
                INSERT IGNORE INTO news (title, url, publish_date, source, description, status, fail_count)
                VALUES (%s, %s, %s, %s, %s, 'N', 0)
                """

                for item in news_list:
                    val = (
                        item['title'],
                        item['url'],
                        item['publish_date'],
                        item['source'],
                        item.get('description', '')
                    )
                    cursor.execute(sql, val)
                    
                    if cursor.rowcount > 0:
                        inserted_count += 1
                
                # é€™ä¸€è¡Œæ˜¯å°‡è³‡æ–™å¯«å…¥ç¡¬ç¢Ÿçš„é—œéµ
                conn.commit()
                logger.info(f"[DB] æ‰¹æ¬¡ä½œæ¥­çµæŸ: è¼¸å…¥ {len(news_list)} ç­† -> å¯¦éš›æ–°å¢ {inserted_count} ç­†")

            except mysql.connector.Error as err:
                # åªæœ‰ç•¶ç™¼ç”Ÿ "åš´é‡éŒ¯èª¤" (å¦‚é€£ç·šæ–·æ‰) æ™‚æ‰ rollback
                # å› ç‚º raise_on_warnings=Falseï¼Œé‡è¤‡è³‡æ–™ä¸æœƒè·‘é€²é€™è£¡
                logger.error(f"[DB Error] å¯«å…¥å¤±æ•—: {err}")
                if conn:
                    conn.rollback()  # <--- ä½ çš„è³‡æ–™å°±æ˜¯åœ¨é€™è£¡æ¶ˆå¤±çš„
            finally:
                if cursor: cursor.close()
                if conn and conn.is_connected(): conn.close()
            
            return inserted_count

        def get_pending_news(self) -> List[Dict]:
            """
            æµç¨‹åœ–æ­¥é©Ÿ 5: ç²å–æ‰€æœ‰ç‹€æ…‹ç‚º 'N' (New) çš„è³‡æ–™ï¼Œæº–å‚™é€²è¡Œå¡«è¡¨
            """
            conn = None
            cursor = None
            results = []
            try:
                conn = self.get_connection()
                cursor = conn.cursor(dictionary=True) # å›å‚³å­—å…¸æ ¼å¼ï¼Œæ–¹ä¾¿å­˜å–æ¬„ä½
                
                # ä¾ç…§æ—¥æœŸæ’åºï¼ŒèˆŠçš„æ–°èå…ˆè™•ç†
                sql = "SELECT * FROM news WHERE status = 'N' ORDER BY publish_date ASC"
                cursor.execute(sql)
                results = cursor.fetchall()
                
            except mysql.connector.Error as err:
                logger.error(f"[DB Error] è®€å–å¾…è™•ç†è³‡æ–™å¤±æ•—: {err}")
            finally:
                if cursor: cursor.close()
                if conn and conn.is_connected(): conn.close()
            return results

        def update_status(self, news_id: int, status: str):
            """
            æµç¨‹åœ–æ­¥é©Ÿ 7: å¡«è¡¨æˆåŠŸå¾Œï¼Œæ›´æ–°ç‹€æ…‹ (ä¾‹å¦‚è®Šæ›´ç‚º 'Y')
            """
            conn = None
            cursor = None
            try:
                conn = self.get_connection()
                cursor = conn.cursor()
                
                sql = "UPDATE news SET status = %s WHERE id = %s"
                cursor.execute(sql, (status, news_id))
                conn.commit()
                logger.info(f"[DB] æ–°è ID {news_id} ç‹€æ…‹æ›´æ–°ç‚º: '{status}'")
                
            except mysql.connector.Error as err:
                logger.error(f"[DB Error] æ›´æ–°ç‹€æ…‹å¤±æ•—: {err}")
            finally:
                if cursor: cursor.close()
                if conn and conn.is_connected(): conn.close()

        def record_failure(self, news_id: int):
            """
            æµç¨‹åœ–å¤±æ•—è¿´åœˆé‚è¼¯: 
            1. å¤±æ•—æ¬¡æ•¸ (fail_count) + 1
            2. è‹¥å¤±æ•—æ¬¡æ•¸ >= 3ï¼Œå°‡ status è¨­ç‚º 'E' (Error/æ”¾æ£„)
            """
            conn = None
            cursor = None
            try:
                conn = self.get_connection()
                cursor = conn.cursor()
                
                # 1. å¢åŠ å¤±æ•—æ¬¡æ•¸
                sql_update = "UPDATE news SET fail_count = fail_count + 1 WHERE id = %s"
                cursor.execute(sql_update, (news_id,))
                
                # 2. æª¢æŸ¥ç›®å‰å¤±æ•—æ¬¡æ•¸
                sql_check = "SELECT fail_count FROM news WHERE id = %s"
                cursor.execute(sql_check, (news_id,))
                result = cursor.fetchone()
                
                if result:
                    current_fail_count = result[0]
                    logger.warning(f"[DB] æ–°è ID {news_id} å¤±æ•—æ¬¡æ•¸å¢åŠ ç‚º: {current_fail_count}")
                    
                    # 3. åˆ¤æ–·æ˜¯å¦è¶…éé–¾å€¼ (ä¾‹å¦‚ 3 æ¬¡)
                    if current_fail_count >= 3:
                        sql_mark_error = "UPDATE news SET status = 'E' WHERE id = %s"
                        cursor.execute(sql_mark_error, (news_id,))
                        logger.error(f"[DB] æ–°è ID {news_id} å¤±æ•—æ¬¡æ•¸éå¤š (>=3)ï¼Œæ¨™è¨˜ç‚º Error (E)")
                
                conn.commit()
                
            except mysql.connector.Error as err:
                logger.error(f"[DB Error] ç´€éŒ„å¤±æ•—æ¬¡æ•¸éŒ¯èª¤: {err}")
            finally:
                if cursor: cursor.close()
                if conn and conn.is_connected(): conn.close()
```

5.è«‹å°‡ä»¥ä¸‹å…§å®¹è¤‡è£½åˆ° app/form_filler.pyï¼Œæ›´æ–°Google Form å¡«è¡¨å™¨  
```text
    import logging
    import os
    import time
    from datetime import datetime, timedelta
    from selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.chrome.options import Options
    from webdriver_manager.chrome import ChromeDriverManager
    from logger import logger

    class FormFiller:
        def __init__(self):
            self.form_url = os.getenv('GOOGLE_FORM_URL')
            if not self.form_url:
                raise ValueError("ç’°å¢ƒè®Šæ•¸ GOOGLE_FORM_URL æœªè¨­å®šï¼")
            
            self.driver = self._setup_driver()

        def _setup_driver(self) -> webdriver.Chrome:
            chrome_options = Options()
            chrome_options.add_argument("--headless=new") 
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            
            chrome_options.add_argument("--blink-settings=imagesEnabled=false")
            chrome_options.add_argument("--disable-gpu")
            chrome_options.add_argument("--disable-extensions")
            chrome_options.add_argument("--window-size=1920,1080")
            
            chrome_options.add_argument("--disable-blink-features=AutomationControlled")
            chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=chrome_options)
            return driver

        def _smart_fill(self, element, value):
            """å˜—è©¦å¤šç¨®æ–¹å¼å¡«å…¥æ•¸å€¼"""
            try:
                element.clear()
                element.send_keys(value)
            except Exception:
                try:
                    element.click()
                    element.send_keys(value)
                except:
                    self.driver.execute_script("""
                        arguments[0].value = arguments[1];
                        arguments[0].dispatchEvent(new Event('input', { bubbles: true }));
                        arguments[0].dispatchEvent(new Event('change', { bubbles: true }));
                    """, element, value)

        def fill_form(self, data: dict) -> bool:
            try:
                logger.info(f"å‰å¾€è¡¨å–®: {self.form_url}")
                self.driver.get(self.form_url)
                
                try:
                    WebDriverWait(self.driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[role="listitem"]')))
                except:
                    logger.warning("è¡¨å–®è¼‰å…¥ä¼¼ä¹è¶…æ™‚ï¼Œä½†å˜—è©¦ç¹¼çºŒå°‹æ‰¾è¼¸å…¥æ¡†...")

                # å¤šé‡å®šä½ç­–ç•¥
                inputs = self.driver.find_elements(By.CSS_SELECTOR, "input.whsOnd")
                if not inputs:
                    inputs = self.driver.find_elements(By.CSS_SELECTOR, "input[type='text']")
                if not inputs:
                    inputs = self.driver.find_elements(By.CSS_SELECTOR, "input[aria-label]")

                textareas = self.driver.find_elements(By.TAG_NAME, 'textarea')

                logger.info(f"åµæ¸¬åˆ° {len(inputs)} å€‹è¼¸å…¥æ¡†")

                if len(inputs) >= 5:
                    # 1. æ¨™é¡Œ
                    self._smart_fill(inputs[0], data['title'])
                    # 2. é€£çµ
                    self._smart_fill(inputs[1], data['url'])
                    # 3. ç™¼å¸ƒæ—¥æœŸ
                    self._smart_fill(inputs[2], str(data['publish_date']))
                    # 4. ä¾†æº
                    self._smart_fill(inputs[3], data['source'])

                    # 5. æ“·å–æ™‚é–“
                    raw_time = data.get('created_at') or data.get('captured_at')
                    if not raw_time: raw_time = datetime.now()
                    if isinstance(raw_time, str):
                        try: raw_time = datetime.strptime(raw_time, '%Y-%m-%d %H:%M:%S')
                        except: raw_time = datetime.now()
                    tw_time = raw_time + timedelta(hours=8)
                    self._smart_fill(inputs[4], tw_time.strftime('%Y-%m-%d %H:%M:%S'))
                    
                    # 6. æ‘˜è¦
                    if textareas and 'description' in data:
                        desc = data['description'][:800] 
                        self._smart_fill(textareas[0], desc)
                    
                    logger.info("æ¬„ä½å¡«å¯«å®Œç•¢ï¼Œå˜—è©¦æäº¤...")
                    
                    # æäº¤æŒ‰éˆ•
                    submit_btn = None
                    btn_xpaths = [
                        "//div[@role='button']//span[text()='æäº¤']",
                        "//div[@role='button']//span[text()='Submit']",
                        "//span[contains(text(), 'æäº¤')]/ancestor::div[@role='button']",
                        "//span[contains(text(), 'Submit')]/ancestor::div[@role='button']"
                    ]
                    
                    for xpath in btn_xpaths:
                        candidates = self.driver.find_elements(By.XPATH, xpath)
                        if candidates:
                            submit_btn = candidates[0]
                            break

                    if submit_btn:
                        self.driver.execute_script("arguments[0].scrollIntoView(true);", submit_btn)
                        time.sleep(1)
                        self.driver.execute_script("arguments[0].click();", submit_btn)
                        
                        # --- [ä¿®æ­£é‡é»] æ”¾å¯¬æˆåŠŸé©—è­‰ ---
                        try:
                            # å˜—è©¦ç­‰å¾…æˆåŠŸè¨Šæ¯
                            wait = WebDriverWait(self.driver, 5)
                            wait.until(EC.presence_of_element_located((By.XPATH, '//div[contains(text(), "å·²è¨˜éŒ„") or contains(text(), "recorded") or contains(text(), "response")]')))
                            logger.info("âœ… åµæ¸¬åˆ°æˆåŠŸé é¢æ–‡å­—")
                            return True
                        except:
                            # å¦‚æœç­‰ä¸åˆ°æ–‡å­—ï¼Œæª¢æŸ¥ç¶²å€æ˜¯å¦æ”¹è®Š (Google Form æäº¤å¾Œç¶²å€æœƒè®Š)
                            current_url = self.driver.current_url
                            if "formResponse" in current_url or "viewform" not in current_url:
                                logger.info("âš ï¸ æœªåµæ¸¬åˆ°æˆåŠŸæ–‡å­—ï¼Œä½†ç¶²å€å·²è®Šæ›´ï¼Œè¦–ç‚ºæäº¤æˆåŠŸ")
                                return True
                            else:
                                # çœŸçš„å¤±æ•—äº†ï¼Œæˆªåœ–ç•™åº•
                                logger.warning("âŒ æäº¤ä¼¼ä¹æ²’åæ‡‰ï¼Œæˆªåœ–æª¢æŸ¥")
                                self.driver.save_screenshot(f"submit_fail_{int(time.time())}.png")
                                return False # é€™è£¡é‚„æ˜¯å›å‚³ Falseï¼Œè®“ä¸»ç¨‹å¼é‡è©¦ï¼Œæˆ–è€…æ‚¨å¯ä»¥æ”¹æˆ True è³­ä¸€æŠŠ
                    else:
                        logger.error("æ‰¾ä¸åˆ°æäº¤æŒ‰éˆ•")
                        return False
                else:
                    logger.error(f"âŒ å¡«è¡¨å¤±æ•—: æ‰¾ä¸åˆ°è¶³å¤ çš„è¼¸å…¥æ¡† (é æœŸ 5 å€‹ï¼Œåªæ‰¾åˆ° {len(inputs)} å€‹)ã€‚")
                    return False

            except Exception as e:
                logger.error(f"âŒ å¡«è¡¨éç¨‹ç™¼ç”Ÿç•°å¸¸: {str(e)[:100]}")
                return False
            finally:
                try:
                    self.driver.quit()
                except:
                    pass
```

6.è«‹å°‡ä»¥ä¸‹å…§å®¹è¤‡è£½åˆ° app/logger.pyï¼Œæ›´æ–°æ—¥èªŒè¨­å®šæ¨¡çµ„  
```text
    import logging
    import os
    import sys
    from logging.handlers import TimedRotatingFileHandler
    from datetime import datetime

    # å®šç¾©æ—¥èªŒè³‡æ–™å¤¾
    LOG_DIR = "logs"
    if not os.path.exists(LOG_DIR):
        os.makedirs(LOG_DIR)

    # å®šç¾©æ—¥èªŒæ ¼å¼
    FORMATTER_STRING = "%(asctime)s - [%(levelname)s] - %(filename)s:%(lineno)d - %(message)s"
    DATE_FORMAT = "%Y-%m-%d %H:%M:%S"

    class LoggerSetup:
        def __init__(self):
            self.logger = logging.getLogger("AsusNewsBot")
            self.logger.setLevel(logging.INFO)
            
            # é˜²æ­¢é‡è¤‡æ·»åŠ  Handler (é¿å… Log é‡è¤‡å°å‡º)
            if not self.logger.handlers:
                self._add_console_handler()
                self._add_file_handler()

        def _add_console_handler(self):
            """æ–°å¢çµ‚ç«¯æ©Ÿè¼¸å‡º"""
            console_handler = logging.StreamHandler(sys.stdout)
            console_handler.setLevel(logging.INFO)
            formatter = logging.Formatter(FORMATTER_STRING, datefmt=DATE_FORMAT)
            console_handler.setFormatter(formatter)
            self.logger.addHandler(console_handler)

        def _add_file_handler(self):
            """æ–°å¢æª”æ¡ˆè¼¸å‡º (æ¯å¤©è¼ªæ›¿ï¼Œæª”ååŒ…å«æ—¥æœŸ)"""
            # ç‚ºäº†è®“æª”åä¸€é–‹å§‹å°±åŒ…å«æ—¥æœŸï¼Œæˆ‘å€‘åœ¨åˆå§‹åŒ–æ™‚å°±è¨­å®šå¥½åŸºç¤æª”å
            # ä¾‹å¦‚: logs/app_2023-12-06.log
            current_date = datetime.now().strftime("%Y-%m-%d")
            filename = os.path.join(LOG_DIR, f"app_{current_date}.log")
            
            # ä½¿ç”¨ TimedRotatingFileHandler
            # when="midnight": æ¯å¤©åˆå¤œè¼ªæ›¿
            # interval=1: æ¯ 1 å¤©
            # backupCount=7: ä¿ç•™æœ€è¿‘ 7 å€‹æª”æ¡ˆ
            # encoding="utf-8": ç¢ºä¿ä¸­æ–‡ä¸äº‚ç¢¼
            file_handler = TimedRotatingFileHandler(
                filename, when="midnight", interval=1, backupCount=7, encoding="utf-8"
            )
            
            # è¨­å®šè¼ªæ›¿å¾Œçš„æª”åå¾Œç¶´æ ¼å¼ (é›–ç„¶æˆ‘å€‘åŸºç¤æª”åå·²æœ‰æ—¥æœŸï¼Œä½†é€™æ˜¯è¼ªæ›¿æ©Ÿåˆ¶çš„æ¨™æº–è¨­å®š)
            file_handler.suffix = "%Y-%m-%d.log" 
            file_handler.setLevel(logging.INFO)
            
            formatter = logging.Formatter(FORMATTER_STRING, datefmt=DATE_FORMAT)
            file_handler.setFormatter(formatter)
            self.logger.addHandler(file_handler)

        def get_logger(self):
            return self.logger

    # åˆå§‹åŒ–ä¸¦åŒ¯å‡º logger å¯¦ä¾‹
    # å…¶ä»–æª”æ¡ˆåªéœ€: from logger import logger å³å¯ä½¿ç”¨
    logger = LoggerSetup().get_logger()
```

7.åŸ·è¡Œ  
  a.åœ¨ Docker è£¡é¢æ‰‹å‹•æ¸¬è©¦çˆ¬èŸ²  
    ```bash
    docker exec -it asus_news_worker python app/main.py  
    ```
    æœ€å¾Œæœƒçœ‹åˆ° Log é¡¯ç¤ºï¼š  === å…¨éƒ¨å®Œæˆ ===  

  b.è‡ªå‹•åŒ–åŸ·è¡Œï¼Œç¨‹å¼è‡ªå‹•è·‘èµ·ä¾†  
    ```bash
    docker-compose up  
    ```

  è¨»:  
  1.è‹¥è¦é–‹ç™¼è€…é€²å…¥æ‰‹å‹•åŸ·è¡Œï¼Œdocker-compose.ymlä¸­æ”¹(command: tail -f /dev/null)å¾Œï¼Œæ‰‹å‹•åŸ·è¡Œdocker exec -it asus_news_worker python app/main.pyã€‚  
  2.å¦‚æœæ˜¯è‡ªå‹•åŒ–ç³»çµ±ï¼Œæ‡‰è©²æ˜¯è¨­å®šç‚ºåŸ·è¡Œ Pythonï¼Œé æœŸ docker-compose up å¾Œç¨‹å¼å°±æœƒè‡ªå‹•è·‘èµ·ä¾†ï¼Œå› æ­¤docker-compose.ymlä¸­è¨­å®š(command: python app/main.py)ã€‚  

8.å¯ä»¥æŸ¥çœ‹ Docker å…§éƒ¨æ—¥èªŒï¼Œè«‹åœ¨çµ‚ç«¯æ©Ÿè¼¸å…¥  
  ```bash
  docker logs -f asus_news_worker
  ```

**=========================================================================================**
ğŸš€ **æŸ¥è©¢çµæœ**  
æœ‰ä¸åŒæ–¹æ³•å¯æŸ¥è©¢çµæœ  
1. è‡³Google Formè¡¨å–®å›æ‡‰ä¸­æŸ¥çœ‹  

2. é€²å…¥ MySQL äº’å‹•ä»‹é¢æŸ¥è©¢  
   (1).è«‹åœ¨ Terminal åŸ·è¡Œï¼Œé€²å…¥å®¹å™¨ä¸¦ç™»å…¥ MySQL  
       ```bash
       docker exec -it asus_news_db mysql -u root -p
       ```
       ç³»çµ±æœƒæç¤ºè¼¸å…¥å¯†ç¢¼ï¼Œè«‹è¼¸å…¥"å¯†ç¢¼"

   (2)çœ‹åˆ° mysql> æç¤ºç¬¦è™Ÿå¾Œï¼Œè¤‡è£½ä»¥ä¸‹æŒ‡ä»¤ï¼Œåˆ‡æ›è³‡æ–™åº«  
      ```bash
      USE security_news;
      ```

   (3)ä¸‹æŒ‡ä»¤ï¼Œæˆ‘è¦ç”¨UTF-8çœ‹  
      ```bash
      SET NAMES utf8mb4;
      ```

   (4)ä¸‹ SQL èªæ³•ï¼ŒæŸ¥çœ‹æ–°èè³‡æ–™ (æª¢æŸ¥çˆ¬èŸ²æˆæœ)  
      ```bash
      SELECT id, title, source, created_at FROM news ORDER BY id;
      ```

   (5)é›¢é–‹  
      ```bash
      exit;
      ```